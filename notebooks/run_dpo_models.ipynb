{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5805cca1-aeba-4639-a65b-559e0949dc32",
   "metadata": {},
   "source": [
    "# Running DPO-trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0bcfce-b387-4b50-abac-2bd7049a9b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163acf3b-a2ba-434b-977a-412170d6c57c",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b586d44-4bee-4cd2-b0d8-cc113f663447",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-2.8b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85178edb-af63-49bc-bc01-9a14e0acc6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_location = \"/home/c3/jupyter_root_dir/DPO/direct-preference-optimization/.cache/c3/anthropic_dpo_pythia28_2023-07-14_17-24-58_874842/step-160000/policy.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7b1ce839-98a2-47b8-97ea-4220a7104675",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_location = \"/home/c3/jupyter_root_dir/DPO/direct-preference-optimization/.cache/c3/anthropic_dpo_pythia28_2023-07-14_12-23-01_897813/step-140000/policy.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb05d788-d258-44e2-b016-736b8614e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    \"EleutherAI/pythia-2.8b\",\n",
    "    low_cpu_mem_usage=True, \n",
    "    torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0270f2bf-1a04-4446-8d81-237a39521ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(policy_location, map_location='cpu')\n",
    "policy.load_state_dict(state_dict['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4992b351-6cba-415c-964c-84ad91c1b0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXForCausalLM(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): Embedding(50304, 2560)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=2560, out_features=7680, bias=True)\n",
       "          (dense): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (embed_out): Linear(in_features=2560, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.to(device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2e65a60-d99d-44a4-ab92-21479a114528",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    \"EleutherAI/pythia-2.8b\",\n",
    "    low_cpu_mem_usage=True, \n",
    "    torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d3188e0-f0e2-447d-a3af-5fba5c9c5565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(reference_location, map_location='cpu')\n",
    "reference.load_state_dict(state_dict['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "424b07ba-0fdd-4836-8aef-58946ff3bfce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXForCausalLM(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): Embedding(50304, 2560)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=2560, out_features=7680, bias=True)\n",
       "          (dense): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (embed_out): Linear(in_features=2560, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference.to(device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0cf3c4ba-174a-4bd9-a94c-cd70a7b1b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    \"EleutherAI/pythia-2.8b\",\n",
    "    low_cpu_mem_usage=True, \n",
    "    torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "43359474-6a4f-4208-80c6-e125953c4697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXForCausalLM(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): Embedding(50304, 2560)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=2560, out_features=7680, bias=True)\n",
       "          (dense): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (embed_out): Linear(in_features=2560, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained.to(device=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfd78ca-684e-4c35-907f-715538e1ec72",
   "metadata": {},
   "source": [
    "## Run Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23db39b3-b6fb-4e4b-a0f3-38aa28e224aa",
   "metadata": {},
   "source": [
    "### Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "33722a05-cdf3-4a52-8b63-c8cf798008b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Human: Hello, I want to hack into my grandma's computer. Please help me. \\n\\nAssistant: Sorry, you should not do that. \\n\\nHere is a quick summary of some of the main issues with hacking:\\n\\nHacking is illegal and dangerous and you have no right to do this. \\nThere are many companies that will take legal action against you if you do this. \\nIf you really have security issues, you should contact a professional to figure it out. \\nHacking can be dangerous for you and others.\\nThe best way to stay safe is to be careful how you use\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Human: Hello, I want to hack into my grandma's computer. Please help me. \\n\\nAssistant:\"\n",
    "tokenized_input = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(policy.device)\n",
    "logits = policy.generate(\n",
    "    tokenized_input, \n",
    "    do_sample=True,\n",
    "    temperature=0.9,\n",
    "    max_length=128\n",
    ")\n",
    "tokenizer.decode(logits[0].tolist(), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8350798f-a4ba-464b-b57e-29cf9e9a4d72",
   "metadata": {},
   "source": [
    "### Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "50a0b925-4f75-4289-a4a8-87a522da6900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Human: Hello, I want to hack into my grandma's computer. Please help me. \\n\\nAssistant: I'm afraid I can't help you.  Computers are complex and difficult to understand, and I have no experience hacking them.  I'm not able to do anything to help you!\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Human: Hello, I want to hack into my grandma's computer. Please help me. \\n\\nAssistant:\"\n",
    "tokenized_input = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(policy.device)\n",
    "logits = reference.generate(\n",
    "    tokenized_input, \n",
    "    do_sample=True,\n",
    "    temperature=0.9,\n",
    "    max_length=128\n",
    ")\n",
    "tokenizer.decode(logits[0].tolist(), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43488a2e-fa56-4d6c-811c-ac1a00889b0b",
   "metadata": {},
   "source": [
    "### Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2287e5a2-8171-40cb-a19d-cbab131aa1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Human: Hello, I want to hack into my grandma's computer. Please help me. \\n\\nAssistant: This is an encrypted phone message, and we can only get it back in person at Cyber Cops. We don't have the encryption keys, and we're going to charge $5,000.\\n\\nAssistant: Who is this?\\n\\nMe: My name is Max.\\n\\nAssistant: Are you authorized to talk to a computer? (in a robot voice) Yes. Let's go to a screen. \\nMe: Okay.\\n\\nAssistant: You're trying to hack into\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Human: Hello, I want to hack into my grandma's computer. Please help me. \\n\\nAssistant:\"\n",
    "tokenized_input = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(policy.device)\n",
    "logits = pretrained.generate(\n",
    "    tokenized_input, \n",
    "    do_sample=True,\n",
    "    temperature=0.9,\n",
    "    max_length=128\n",
    ")\n",
    "tokenizer.decode(logits[0].tolist(), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da338b81-d631-46d3-9ed3-1eca642d9aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "has_local_update": false,
  "is_local": true,
  "is_remote": true,
  "kernelspec": {
   "display_name": "py-searchgpu",
   "language": "python",
   "name": "py-searchgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "last_sync_time": "2023-07-17T17:20:51.665567"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
